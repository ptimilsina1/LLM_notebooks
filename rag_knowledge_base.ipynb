{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c12499-405f-43a7-90cd-e2de16ed7c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can access the OpenAI API key using os.getenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1330333e-493d-4fe2-9c83-97f16e11e0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: forecasting inventory management in e-commerce\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def extract_topic(sentence):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Filter out stopwords and punctuation\n",
    "    keywords = [token.text for token in doc if not token.is_stop and not token.is_punct and token.pos_ in ['NOUN']]\n",
    "    \n",
    "    # Join the keywords into a single string\n",
    "    topic = ' '.join(keywords)\n",
    "    \n",
    "    return topic\n",
    "\n",
    "# Example usage\n",
    "domain = 'e-commerce'\n",
    "sentence = \"Help me do better demand forecasting and inventory management\"\n",
    "topic = extract_topic(sentence)+' in '+domain\n",
    "print(\"Topic:\", topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3df9f26-48f4-4cfb-81fb-da113cb44721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader, PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb5f37d-4fc3-441e-bd5f-cf6a73aed6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./pdf_knowledge_base\\test1.pdf test1.pdf\n",
      "./pdf_knowledge_base\\test2.pdf test2.pdf\n",
      "./pdf_knowledge_base\\test3.pdf test3.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Replace 'folder_path' with the path to your folder containing the PDF files\n",
    "folder_path = './pdf_knowledge_base'\n",
    "pdf_files = glob.glob(folder_path + '/*.pdf')\n",
    "\n",
    "# Iterate over both file paths and filenames simultaneously\n",
    "for path, file in zip(pdf_files, [os.path.basename(file) for file in pdf_files]):\n",
    "    print(path, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7f616d2-4fa2-48fd-953e-d9c4f77329d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./db/test1_Knoweldge_base\n",
      "./db/test2_Knoweldge_base\n",
      "./db/test3_Knoweldge_base\n"
     ]
    }
   ],
   "source": [
    "folder_path = './pdf_knowledge_base'\n",
    "pdf_files = glob.glob(folder_path + '/*.pdf')\n",
    "\n",
    "# Iterate over both file paths and filenames simultaneously\n",
    "for path, file in zip(pdf_files, [os.path.basename(file) for file in pdf_files]):\n",
    "    file_name_without_extension = os.path.splitext(file)[0] \n",
    "    # Load Documents\n",
    "    loader = PyPDFLoader(path)\n",
    "    docs = loader.load()\n",
    "\n",
    "\n",
    "    # Split\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    # Embed and store the texts\n",
    "    # Supplying a persist_directory will store the embeddings on disk\n",
    "    persist_directory = './db/'+file_name_without_extension+'_Knoweldge_base'\n",
    "\n",
    "    print(persist_directory)\n",
    "\n",
    "    ## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
    "    embedding = OpenAIEmbeddings()\n",
    "\n",
    "    vectordb = Chroma.from_documents(documents=splits, \n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)\n",
    "    vectordb.persist()\n",
    "    vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5e8163a-8331-46d8-a1e6-2228c7135aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal. \n",
    "vectordb = None\n",
    "vectordb = Chroma(persist_directory=\"./db/test1_Knoweldge_base\", \n",
    "                  embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d155eeed-5233-4556-98ab-7c0f19cb90b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46d97418-854b-4402-886c-d41e34912902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Procurement and Supplier Management involves managing procurement processes and relationships with suppliers. It includes activities such as issuing purchase orders and monitoring inventory levels. Effective management can lead to better supply chain management and faster order fulfillment.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### RETRIEVAL and GENERATION ####\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = 'what is Procurement and Supplier Management?'\n",
    "\n",
    "rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6568c614-ff61-45dc-81f3-7037bd96c43f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
